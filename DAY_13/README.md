-----

### ðŸ“ Day 13: Merge Sort Notes

#### \#\# The "Divide and Conquer" Sorting Master

**Merge Sort** is an efficient, comparison-based sorting algorithm. It's a classic example of a **divide and conquer** strategy, which breaks a problem down into smaller, more manageable subproblems, solves them, and then combines the results.

**Analogy: Sorting a Large Deck of Cards with Friends** ðŸƒ
Imagine you have a huge, shuffled deck of cards. Itâ€™s too big to sort efficiently by yourself.

1.  **Divide:** You split the deck in half and give one half to a friend. You both then split your smaller decks in half again and pass them to other friends. This continues until everyone is holding just a single card. A single card is, by definition, already sorted.
2.  **Conquer & Combine:** Now, the process reverses. You and a friend take your single cards and merge them into a perfectly sorted pile of two. Then, two people with sorted piles of two merge them into a sorted pile of four. This continues up the chain until you and your original friend merge your two large, sorted halves back into one, perfectly sorted deck.

#### \#\# The Two Key Functions

The implementation of Merge Sort naturally splits into two main functions: a recursive "manager" that divides the work, and a "worker" that does the merging.

1.  **`mergeSort(arr, left, right)` - The Recursive "Manager"**

      * This function's only job is to recursively split the array into halves until it can't be split anymore.
      * **Base Case:** If the sub-array has 0 or 1 element (`left >= right`), it's already sorted, so the function simply returns.
      * **Divide Step:**
        1.  Find the middle point of the current sub-array.
        2.  Call `mergeSort` on the left half (`left` to `mid`).
        3.  Call `mergeSort` on the right half (`mid + 1` to `right`).
      * **Combine Step:** Once the two recursive calls return (meaning both halves are now sorted), call `merge(arr, left, mid, right)` to combine them.

2.  **`merge(arr, left, mid, right)` - The "Worker"**

      * This is where the real work happens. This function takes two adjacent, sorted sub-arrays (`arr[left...mid]` and `arr[mid+1...right]`) and merges them into a single sorted sub-array.
      * It requires a temporary array to build the sorted sequence without overwriting the original data prematurely.
      * It uses a three-pointer approach: one pointer for the left half, one for the right half, and one for the current position in the main array. It compares the elements at the left and right pointers, copies the smaller one into the temp array, and advances the corresponding pointer.
      * After the main loop, it copies any remaining elements from the left or right half and then copies the entire sorted temp array back into the original array.

#### \#\# Complexity Analysis

  * **Time Complexity: `O(n log n)`**
    This is true for the best, average, and worst cases, making Merge Sort very reliable. The `log n` comes from the number of times the array is split in half. The `n` comes from the work done at each "level" of splits by the `merge` function, which has to touch every element.
  * **Space Complexity: `O(n)`**
    This is the main trade-off. Merge Sort's speed and stability come at the cost of requiring extra memory for the temporary array used during the merge step.

-----
